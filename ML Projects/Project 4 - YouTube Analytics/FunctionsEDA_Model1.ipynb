{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 1:Target Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func2: Function to Generate the stats pf The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numericsflots = ['float16', 'float32', 'float64']\n",
    "nonnumerics =['object']\n",
    "date=['datetime64[ns]','datetime64']\n",
    "nonnumericsAnddate=['object','datetime64[ns]']\n",
    "\n",
    "def CalBasicStats(Source_DF,type):\n",
    "    data = Source_DF\n",
    "    newdf = pd.DataFrame()\n",
    "    Resultdf= pd.DataFrame()\n",
    "\n",
    "    if type=='numeric':\n",
    "        Traversedf = data.select_dtypes(include=numerics)\n",
    "\n",
    "        for i in Traversedf.columns:\n",
    "            \n",
    "        \n",
    "        #newdf['DataSourceName']=[name]\n",
    "            newdf['ColumnName']=[i]\n",
    "\n",
    "            newdf['AllCounts'] = Traversedf[i].size\n",
    "            newdf['NotNullCounts'] = Traversedf[i].count()\n",
    "            newdf['UniqueCounts'] = Traversedf[i].nunique()\n",
    "            \n",
    "            newdf[\"%Zero\"] = ((Traversedf[i] == 0).sum()/Traversedf[i].size)*100\n",
    "            newdf[\"%Missing\"]= 100-(Traversedf[i].count() / Traversedf[i].size)*100\n",
    "\n",
    "            \n",
    "            newdf['Min']=np.amin(Traversedf[i])\n",
    "            newdf['Max']=np.amax(Traversedf[i])\n",
    "            newdf['Mean']=np.mean(Traversedf[i])\n",
    "\n",
    "            newdf['Average']=np.average(Traversedf[i])\n",
    "\n",
    "            newdf['Median']=np.nanmedian(Traversedf[i],axis=0)\n",
    "            newdf['StddDev']=np.std(Traversedf[i],axis=0)\n",
    "            newdf['Var']=np.var(Traversedf[i],axis=0)\n",
    "\n",
    "            newdf['Skewness']=skew(Traversedf[i].dropna())\n",
    "\n",
    "            newdf['Kurtosis']=kurtosis(Traversedf[i].dropna())\n",
    "    \n",
    "            newdf['25Percentile'] = np.nanpercentile(Traversedf[i], 25,axis=0)\n",
    "            newdf['50Percentile'] = np.nanpercentile(Traversedf[i], 50,axis=0)\n",
    "            newdf['75Percentile'] = np.nanpercentile(Traversedf[i], 75,axis=0)\n",
    "            \n",
    "            \n",
    "            # Resultdf=Resultdf.append(newdf)\n",
    "            Resultdf=pd.concat((Resultdf, newdf), axis = 0)\n",
    "        #newdf[\"UniueRecords\"]=pd.count(Traversedf[i])\n",
    "        return Resultdf\n",
    "\n",
    "    else:\n",
    "        Traversedf = data.select_dtypes(include=nonnumerics) \n",
    "\n",
    "        for i in Traversedf.columns:\n",
    "                # print(i)\n",
    "        #newdf['DataSourceName']=[name]\n",
    "            newdf['ColumnName']=[i]\n",
    "            newdf['AllCounts'] = Traversedf[i].size\n",
    "            newdf['NotNullCounts'] = Traversedf[i].count()\n",
    "            newdf['UniqueCounts'] = Traversedf[i].nunique()\n",
    "\n",
    "            newdf[\"%Missing\"]= 100-(Traversedf[i].count() / Traversedf[i].size)*100\n",
    "\n",
    "            Resultdf=pd.concat((Resultdf, newdf), axis = 0)     \n",
    "\n",
    "        return Resultdf\n",
    "\n",
    "# outdf_numeric = CalBasicStats(Sourcedf,'numeric')\n",
    "# outdf_nonnumeric = CalBasicStats(Sourcedf,'Non-numeric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 3: Handling Missing values and outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plots for all variables \n",
    "def CustomPlots(data,plot='hist'):\n",
    "    colslist=data.columns.to_list()\n",
    "    # row=math.floor(len(colslist)/4)+1\n",
    "\n",
    "    if plot=='hist':\n",
    "        col=4\n",
    "        row=len(colslist)//col  + math.ceil((len(colslist)%col)/col)\n",
    "        fig,ax=plt.subplots(nrows=row, ncols=col,figsize=(15,row*(col*0.75)))\n",
    "        axes = ax.flatten()\n",
    "        for prog, ax in zip(colslist, axes):\n",
    "            ax = sns.histplot(data[prog], kde=True, color='g',ax=ax)\n",
    "\n",
    "               \n",
    "    elif plot=='box':\n",
    "        col=4\n",
    "        row=len(colslist)//col  + math.ceil((len(colslist)%col)/col)\n",
    "        fig,ax=plt.subplots(nrows=row, ncols=col,figsize=(12,row*(col*0.75)))\n",
    "        axes = ax.flatten()\n",
    "        for prog, ax in zip(colslist, axes):\n",
    "            ax = sns.boxplot(data[prog], color='g',ax=ax).set(xlabel=prog)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data_frame, column_name):\n",
    "    # Calculate the IQR for the specified column\n",
    "    Q1 = data_frame[column_name].quantile(0.25)\n",
    "    Q3 = data_frame[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # Define the lower and upper bounds for valid data points\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Remove data points above the upper bound\n",
    "    DF =  data_frame[(data_frame[column_name] >= lower_bound) & (data_frame[column_name] <= upper_bound)]\n",
    "\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func4: Correlation Plots (Numeric Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrAttributesList(data,Target,ThreshHold):\n",
    "    EDA_df=data \n",
    "    correlation_values_P= EDA_df.corr(method='peason')[Target]\n",
    "    correlation_values_S= EDA_df.corr(method='spearman')[Target]\n",
    "    EDA_concatenated_Correlation_df = pd.concat([correlation_values_P, correlation_values_S], axis=1,keys=['Pearson', 'Spearman'])\n",
    "\n",
    "    for i in EDA_concatenated_Correlation_df.columns :\n",
    "        j='Abs'+i\n",
    "        EDA_concatenated_Correlation_df[j]=abs(EDA_concatenated_Correlation_df[i])\n",
    "    Selected = EDA_concatenated_Correlation_df[(EDA_concatenated_Correlation_df[\"AbsPearson\"]>ThreshHold) \n",
    "                                           | (EDA_concatenated_Correlation_df[\"AbsSpearman\"]>ThreshHold)] \n",
    "                                  \n",
    "    Selected_list=Selected.index\n",
    "\n",
    "    return Selected_list,Selected\n",
    "\n",
    "\n",
    "\n",
    "# # Need to write a better function \n",
    "\n",
    "def remove_highly_correlated_features(df, threshold):\n",
    "    corr_matrix = df.corr().abs()  # Calculate the correlation matrix\n",
    "    upper = corr_matrix.where(pd.np.triu(pd.np.ones(corr_matrix.shape), k=1).astype(bool))    \n",
    "    # Find columns to drop\n",
    "    drop_cols = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    print(drop_cols)\n",
    "    # Remove highly correlated features\n",
    "    df_filtered = df.drop(columns=drop_cols)\n",
    "    return df_filtered\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func5 : non Numeric Values Correaltion and (or label encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func6 : Bi Variate using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (986959676.py, line 144)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 144\u001b[0;36m\u001b[0m\n\u001b[0;31m    color='#FFFFFF'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def RangeCalc(min,max):\n",
    "    if min==max:\n",
    "            return min\n",
    "    if np.isnan(min) ==True or np.isnan(max) ==True :\n",
    "            return 'Missing'  \n",
    "    else:\n",
    "            min = float(min)\n",
    "            max = float(max)\n",
    "            suffixes = ['', 'K', 'M']\n",
    "            magnitude_min = 0\n",
    "            magnitude_max = 0\n",
    "            while abs(min) >= 1000 and magnitude_min < len(suffixes)-1:\n",
    "                min /= 1000\n",
    "                magnitude_min += 1\n",
    "            while abs(max) >= 1000 and magnitude_max < len(suffixes)-1:\n",
    "                max /= 1000\n",
    "                magnitude_max += 1\n",
    "            min = '{:.1f}{}'.format(min, suffixes[magnitude_min])\n",
    "            max = '{:.1f}{}'.format(max, suffixes[magnitude_max])\n",
    "            min=str(min)\n",
    "            max=str(max)\n",
    "            return min +' to ' + max\n",
    "\n",
    "def DtreeCreator(Sourcedf,var1,Target,debth=2,M='Classifier'):\n",
    "\n",
    "    TreeDf=pd.DataFrame()\n",
    "    TreeDf_NA_P=pd.DataFrame()\n",
    "\n",
    "    #Prepping the data For Dtree\n",
    "    EDA_df=Sourcedf\n",
    "    TreeDf=EDA_df[[var1,Target]]\n",
    "    TreeDf_NA_P=EDA_df[[var1,Target]]\n",
    "    TreeDf_NA=TreeDf_NA_P[TreeDf_NA_P[var1].isna()]\n",
    "    TreeDf=TreeDf.dropna()\n",
    "    TreeDf.rename(columns = {var1:'X',Target:'Y'}, inplace = True)\n",
    "    TreeDf_NA.rename(columns = {var1:'X',Target:'Y'}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "    # Split the data into independent variables (X) and the target variable (y)\n",
    "    X = TreeDf[['X']]\n",
    "    y = TreeDf['Y']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create the decision tree regressor\n",
    "    if M=='Regressor':\n",
    "        model = DecisionTreeRegressor(max_depth=debth, ccp_alpha=0.0, max_features=None)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    else :\n",
    "        model = DecisionTreeClassifier(max_depth=debth,min_samples_leaf= int(0.015 *len(TreeDf))) #.015 \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    # Predict the target variable for the test data\n",
    "\n",
    "    if M=='Regressor':\n",
    "        y_pred = model.predict(X_test)\n",
    "        TreeDf['Pred']= model.predict(TreeDf[['X']])\n",
    "    else :\n",
    "        y_pred = model.predict(X_test)\n",
    "        TreeDf['Pred']= model.predict_proba(TreeDf[['X']])[:, 1]\n",
    "\n",
    "\n",
    "    #Creating the Final result and bucket \n",
    "\n",
    "    Pred_Unique=TreeDf[\"Pred\"].unique()\n",
    "    newdf=pd.DataFrame()\n",
    "    newdfnewdf2=pd.DataFrame()\n",
    "    Resultdf=pd.DataFrame()\n",
    "\n",
    "\n",
    "    for i in Pred_Unique:\n",
    "        newdf['Pred']=[i]\n",
    "        newdf['VariableName']=var1\n",
    "        newdf['X_min']=np.amin(TreeDf[\"X\"][TreeDf[\"Pred\"]==i])\n",
    "        newdf['X_max']=np.amax(TreeDf[\"X\"][TreeDf[\"Pred\"]==i])\n",
    "        newdf['Counts']=np.size(TreeDf[\"X\"][TreeDf[\"Pred\"]==i])\n",
    "        newdf['Counts%']=round(((np.size(TreeDf[\"X\"][TreeDf[\"Pred\"]==i])/len(EDA_df))*100),1)\n",
    "        Resultdf=pd.concat((Resultdf, newdf), axis = 0)\n",
    "\n",
    "    # TreeDf=TreeDf.dropna()\n",
    "\n",
    "    newdf['Pred']=np.mean(TreeDf_NA[\"Y\"])\n",
    "    newdf['VariableName']=var1\n",
    "    newdf['X_min']=np.amin(TreeDf_NA[\"X\"])\n",
    "    newdf['X_max']=np.amax(TreeDf_NA[\"X\"])\n",
    "    newdf['Counts']=np.size(TreeDf_NA[\"X\"])\n",
    "    newdf['Counts%']=round(((np.size(TreeDf_NA[\"X\"])/len(EDA_df))*100),1)\n",
    "\n",
    "\n",
    "    Resultdf=pd.concat((Resultdf, newdf), axis = 0)\n",
    "\n",
    "    Resultdf = Resultdf[Resultdf['Counts%']>2]\n",
    "\n",
    "    #Post processing and Close \n",
    "\n",
    "    Resultdf[\"X_min\"]=Resultdf[\"X_min\"].round(2)\n",
    "    Resultdf[\"X_max\"]=Resultdf[\"X_max\"].round(2)\n",
    "    Resultdf=Resultdf.sort_values(\"X_min\")\n",
    "    Resultdf[\"Pred\"]=Resultdf[\"Pred\"].round(2)\n",
    "    Resultdf[\"Counts%\"]=Resultdf[\"Counts%\"].astype(str) + '% obs'\n",
    "    # Resultdf[\"Pred\"]= Resultdf['Pred'].apply(lambda x: '0' if x== 0.0 else x)\n",
    "\n",
    "    Resultdf['Range'] = Resultdf.apply(lambda row: RangeCalc(row['X_min'], row['X_max']), axis=1)\n",
    "    return Resultdf,model\n",
    "\n",
    "\n",
    "\n",
    "# Dtree Creation   \n",
    "def PlotDtreeGraph2(data,Prefix=''):\n",
    "\n",
    "    Resultdf=data \n",
    "    Maxy=data['Pred'].max()+0.20\n",
    "    \n",
    "    # create a Dictionary for Order Calculation \n",
    "    order=[]\n",
    "    for i in range(0, len(Resultdf)):\n",
    "        order.append(i)\n",
    "\n",
    "    # XOrder=data['Range'].tolist()\n",
    "    Title=data['VariableName'].iloc[0] + ' ' + Prefix\n",
    "    # Title=Prefix\n",
    "    print(Title)\n",
    "\n",
    "    bar_plot = alt.Chart(Resultdf).mark_bar(color='#006E7F',stroke='black').encode(\n",
    "        x=alt.X('Range',axis=alt.Axis(labelAngle=0),sort=alt.EncodingSortField(field='yield', order='descending')),\n",
    "        y=alt.Y('Pred',title='Downsell'),\n",
    "        tooltip=['Range','Pred','Counts'],\n",
    "    )\n",
    "    pred_labels = bar_plot.mark_text(\n",
    "        align='center',\n",
    "        baseline='bottom',\n",
    "        dy=-5,  # Offset the text labels slightly above the bars\n",
    "    ).encode(\n",
    "        text='Pred'\n",
    "    )\n",
    "    count_label = bar_plot.mark_text(\n",
    "        align='center',\n",
    "        baseline='bottom',\n",
    "        dy=25,  # Offset the text labels slightly above the bars\n",
    "    ).encode(\n",
    "        text='Counts%'\n",
    "        color='#FFFFFF'\n",
    "    )\n",
    "    chart = (bar_plot + pred_labels +count_label).properties(width=650, height=300)\n",
    "\n",
    "    # Adjust the range of the y-axis to zoom out the bars\n",
    "    chart = chart.configure_axis(\n",
    "        grid=False).encode(y=alt.Y('Pred', scale=alt.Scale(domain=(0, Maxy))))\n",
    "\n",
    "    chart = chart.properties(title=Title)\n",
    "    return display(chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func7 : Bivariate using Bars (or scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 8 : Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ConfusionMatrix(cm):\n",
    "    bright_green_colormap = LinearSegmentedColormap.from_list(\n",
    "        'bright_green', [(0, '#E5F5E0'), (0.5, '#80B6A1'), (1, '#293E40')])\n",
    "\n",
    "\n",
    "    # confusion matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=bright_green_colormap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=[0, 1], yticks=[0, 1], xlabel=\"Predicted\", ylabel=\"True\")\n",
    "    ax.xaxis.set_ticklabels(['Class 0', 'Class 1'])\n",
    "    ax.yaxis.set_ticklabels(['Class 0', 'Class 1'])\n",
    "\n",
    "    # confusion matrix cells with the counts\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 9 : Eval Matrix \n",
    "\n",
    "<!-- # def plot_ConfusionMatrix(cm):\n",
    "#     bright_green_colormap = LinearSegmentedColormap.from_list(\n",
    "#         'bright_green', [(0, '#E5F5E0'), (0.5, '#80B6A1'), (1, '#293E40')])\n",
    "\n",
    "\n",
    "#     # confusion matrix\n",
    "#     fig, ax = plt.subplots()\n",
    "#     im = ax.imshow(cm, interpolation='nearest', cmap=bright_green_colormap)\n",
    "#     ax.figure.colorbar(im, ax=ax)\n",
    "#     ax.set(xticks=[0, 1], yticks=[0, 1], xlabel=\"XGBPredicted-INS\", ylabel=\"True\")\n",
    "#     ax.xaxis.set_ticklabels(['Class 0', 'Class 1'])\n",
    "#     ax.yaxis.set_ticklabels(['Class 0', 'Class 1'])\n",
    "\n",
    "#     # confusion matrix cells with the counts\n",
    "#     thresh = cm.max() / 2\n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             ax.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\",\n",
    "#                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.show() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 10 : Shapley matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 11 : Feature Importance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 12 : Summary of Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
