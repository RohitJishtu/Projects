--Fiddler 

Q1: What provider(s) of AI observability platforms (WhyLabs, Aporia, Fiddler AI, ArthurAI, etc.) do you have experience or familiarity with? Please rate your ability to differentiate features for those relevant on a scale of 1-10, 10 being a subject matter expert. Please list for each tools
- A: 

Familiarity Level: 8/10
Elaboration: I have substantial experience with Fiddler AI, making me quite proficient in differentiating its features compared to other platforms like WhyLabs, Aporia, and ArthurAI. Fiddler AI is known for its robust explainability tools, enabling users to understand and trust their AI models through comprehensive monitoring and bias detection. I can discuss its model performance monitoring, anomaly detection, and the actionable insights it provides to improve model accuracy and fairness.



Q2: Are you a current paying customer of any of these providers, and have you used others before? Please specify which, and in what roles/company you used each. Please elaborate

Elaboration: I am currently using Fiddler AI in my projects at ServiceNow. My role involves leveraging this platform to ensure our machine learning models are reliable, fair, and transparent. Previously, I haven't been a paying customer of other AI observability platforms, but my in-depth work with Fiddler AI involves regular interaction with its features and capabilities, thereby enhancing our AI model governance and performance.



Q3:Were you part of the procurement evaluation and decision-making process when deciding which solution to implement (or renew a contract with)? If yes, who did you evaluate/select, against what criteria, and what were the ultimate drivers for your decision? Please elaborate
- A: 
Elaboration: I played a significant role in the procurement and evaluation process when we decided to implement Fiddler AI at ServiceNow. We evaluated multiple solutions based on several criteria:
Operations and Metrics Calculation: How effectively the platform could calculate and display various operational metrics.
Simplicity of Usage: The user-friendliness of the interface and ease of integration with our existing systems.
Economic Factors: Cost-effectiveness and return on investment.
Interpretability: The depth and clarity of insights provided into model behaviors and decisions.
Ultimately, Fiddler AI was chosen for its superior interpretability features and the overall balance it offered across our evaluation criteria.




Q4: Can you briefly describe your company's use case for this provider's solution and the capacity you leverage it daily/weekly/monthly? How many other team members use this tool within their primary workflow? Please elaborate
- A:
In my company, Fiddler AI is used primarily for monitoring our machine learning models. We rely on it daily to ensure our models are performing as expected and to quickly identify any issues or biases that might arise. On a weekly basis, we review detailed reports and insights generated by Fiddler AI to adjust and optimize our models. My team consists of about 20 members who use this tool as an integral part of their workflow, making it essential for maintaining the health and performance of our AI systems.


What is your availability for the rest of this week and next week?
- A: Available in Friday , Sata nd Sunday (9AM-8PM IST)
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



--GenAI USe cas 

Can you please elborate my rough answers to below 4 questions in 1-3 sentences 

Q:Does your organization have any Gen AI use case in PoC or deployed in a live environment?

Yes we have a few use cases , one of them is meeting assist program using gen AI , Based on lead's surf data for us we are trying to give best notes for a rep for his meetingb 

Q:Can you speak in detail about the tech stack (Infra/hardware/cloud, Data services, Models, ModelOps/Middleware, Applications and Consulting services) used to implement Gen AI for these use cases and factors considered to implement the tech stack in a particular way/with a particular vendor? Please provide an example

We used the below libs along with Chat GPT 4 APi to call LLM 

from langchain.llms.base import LLM
from sentence_transformers import SentenceTransformer
from sentence_transformers.util import dot_score, semantic_search
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.prompts.chat import ChatMessagePromptTemplate, HumanMessagePromptTemplate

Q:Can you speak in detail about what is working well and not working well in these implementations from an architectural standpoint? Please provide an example.

Controlling hallucination is a challange , for business level answers we need to tweak answers a lbit 

Q:Can you speak about the estimated/actual split in % spend for each layer of the tech stack (Infra/hardware/cloud, Data services, Models, ModelOps/Middleware, Applications and Consulting services)?


Database Snowflake - 25% 
Azure ML for LLM API hosting - 40% 
Dashboarding/UI -  20%

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



Describe the impact you have had on the company and customers of your current or most recent role?*

Give an example of an ML project that you led. Specify what parts of this you did by yourself*


1: Are you involved in post-training models that require mechanistic interpretability or model steering?
2: Are you actively involved in the model steering or mechanistic interpretability process at current or prior companies in some capacity?
3: Rate your familiarity on 1-5 with Goodfire, Dmodel
4: What is your availability and rate?