{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "from werkzeug.exceptions import BadRequest\n",
    "import logging\n",
    "from threading import Thread\n",
    "import socket\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_model= joblib.load('/Users/rohit.jishtu/Documents/GitHub/NewMachine/Projects/ML Projects/Project 7 - Bank Marketing Data/BankDtreeModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask server is running on http://127.0.0.1:49597\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:49597\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 16:23:47] \"GET /health HTTP/1.1\" 200 -\n",
      "/Users/rohit.jishtu/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "ERROR:__main__:Prediction error: X has 4 features, but DecisionTreeClassifier is expecting 41 features as input.\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 16:23:47] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "from werkzeug.exceptions import BadRequest\n",
    "import logging\n",
    "from threading import Thread\n",
    "import socket\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to find an available port\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))\n",
    "        s.listen(1)\n",
    "        port = s.getsockname()[1]\n",
    "    return port\n",
    "\n",
    "# Initialize Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model when starting the server\n",
    "model = None\n",
    "\n",
    "def load_model():\n",
    "    global model\n",
    "    try:\n",
    "        model = ML_model\n",
    "        logger.info(\"Model loaded successfully!\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"Error: model.joblib not found. Please ensure model file exists.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Load model at startup\n",
    "load_model()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if model is None:\n",
    "        return jsonify({\n",
    "            'status': 'error',\n",
    "            'message': 'Model not loaded'\n",
    "        }), 503\n",
    "    \n",
    "    try:\n",
    "        # Get data from request\n",
    "        data = request.get_json()\n",
    "        \n",
    "        # Validate input\n",
    "        if not data or 'features' not in data:\n",
    "            raise BadRequest('Request must include \"features\" key')\n",
    "            \n",
    "        features = np.array(data['features']).reshape(1, -1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(features)\n",
    "        \n",
    "        # Return prediction as JSON\n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'prediction': prediction.tolist()\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prediction error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            'status': 'error',\n",
    "            'message': str(e)\n",
    "        }), 400\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\n",
    "        'status': 'healthy', \n",
    "        'model_loaded': model is not None\n",
    "    })\n",
    "\n",
    "# Find an available port\n",
    "PORT = find_free_port()\n",
    "\n",
    "# Function to run the Flask app in a thread\n",
    "def run_app():\n",
    "    app.run(host='127.0.0.1', port=PORT, debug=False, use_reloader=False)\n",
    "\n",
    "# Start the Flask app in a separate thread\n",
    "server_thread = Thread(target=run_app)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "print(f\"Flask server is running on http://127.0.0.1:{PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health check: {'model_loaded': True, 'status': 'healthy'}\n",
      "Prediction: {'message': 'X has 4 features, but DecisionTreeClassifier is expecting 41 features as input.', 'status': 'error'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Get the port number from the previous output\n",
    "PORT = 49597  # Replace this with the port number shown in the output\n",
    "\n",
    "# Test the health endpoint\n",
    "response = requests.get(f'http://127.0.0.1:{PORT}/health')\n",
    "print(\"Health check:\", response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the predict endpoint\n",
    "data = {\"features\": [1, 2, 3, 4]}\n",
    "response = requests.post(f'http://127.0.0.1:{PORT}/predict', json=data)\n",
    "print(\"Prediction:\", response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
